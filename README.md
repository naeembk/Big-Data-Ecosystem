#  Introduction to Spark with PySpark

This project is a hands-on tutorial and lab for understanding how to work with **Apache Spark** using **PySpark** in Python. It walks you through key Spark components including DataFrames, RDDs, and basic ML operations using Spark's machine learning library.

---

## üéØ Learning Objectives

By completing this lab, you will be able to:

- Program in Spark using the Python (PySpark) API
- Read and process data using Spark SQL and DataFrames
- Compare RDDs vs DataFrames
- Build a simple machine learning pipeline using Spark MLlib

---

## ‚öôÔ∏è Requirements

**Recommended Environment:** Google Colab (no local setup needed)

### If running locally:
Install dependencies:
```bash
pip install findspark
pip install pyspark
